{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8437e475-c6ec-49d7-9328-bcc15f7fca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3962b71-77bd-4c1e-883a-aa86f33ed9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "local_zip = './horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('./horse-or-human')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca8cc89-0cdd-463d-836a-a8e14a4d43c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_horse_dir = os.path.join('./horse-or-human/horses')\n",
    "\n",
    "train_human_dir = os.path.join('./horse-or-human/humans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5a608f-38fe-4d7d-a558-c02974369f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_horse_names = os.listdir(train_horse_dir)\n",
    "print(train_horse_names[:10])\n",
    "\n",
    "train_human_names = os.listdir(train_human_dir)\n",
    "print(train_human_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f888601-348e-4f23-b055-0ab5a6ecea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total training horse images:', len(os.listdir(train_horse_dir)))\n",
    "print('total training human images:', len(os.listdir(train_human_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ff86a-389f-4421-a1c8-bcaecba799bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7307f1f9-1bda-4794-8b06-97440579bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "\n",
    "  model = tf.keras.models.Sequential()\n",
    "\n",
    "  model.add(tf.keras.layers.Conv2D(\n",
    "    filters= 16,\n",
    "    kernel_size = (3, 3),\n",
    "    activation=\"relu\",\n",
    "    input_shape = (300, 300, 3)\n",
    "  ))\n",
    "\n",
    "  model.add(tf.keras.layers.MaxPool2D(\n",
    "      pool_size=(2, 2),\n",
    "      strides=2\n",
    "  ))\n",
    "\n",
    "  model.add(tf.keras.layers.Conv2D(\n",
    "    filters= 32,\n",
    "    kernel_size = (3, 3),\n",
    "    activation=\"relu\",\n",
    "    input_shape = (300, 300, 3)\n",
    "  ))\n",
    "\n",
    "  model.add(tf.keras.layers.MaxPool2D(\n",
    "      pool_size=(2, 2),\n",
    "      strides=2\n",
    "  ))\n",
    "\n",
    "  model.add(tf.keras.layers.Conv2D(\n",
    "    filters= 64,\n",
    "    kernel_size = (3, 3),\n",
    "    activation=\"relu\"\n",
    "  ))\n",
    "\n",
    "  model.add(tf.keras.layers.MaxPool2D(\n",
    "      pool_size=(2, 2),\n",
    "      strides=2\n",
    "  ))\n",
    "\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(\n",
    "      units = 512,\n",
    "      activation=\"relu\"\n",
    "      ))\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(\n",
    "      units = 1,\n",
    "      activation=\"sigmoid\"\n",
    "      ))\n",
    "\n",
    "  model.compile(\n",
    "      loss = \"binary_crossentropy\",\n",
    "      optimizer = \"rmsprop\",\n",
    "      metrics = [\"accuracy\"]\n",
    "      )\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3afdc9-c21f-48d0-92f1-a4925300a8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    ")\n",
    "\n",
    "train = train.flow_from_directory(\n",
    "    './horse-or-human/',\n",
    "    class_mode=\"binary\",\n",
    "    batch_size=128,\n",
    "    target_size=(300, 300)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd9fc0-2910-4f8d-a9b3-ef1c72fc62b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = model()\n",
    "history = cnn.fit(\n",
    "      train,\n",
    "      steps_per_epoch=8,\n",
    "      epochs=15,\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5992717-34d6-4e50-a052-473dd0a02543",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64facabc-2a86-4e80-88ba-ad5f131ceb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google.colab import files\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "\n",
    "  path = '/content/' + fn\n",
    "  img = load_img(path, target_size=(300, 300))\n",
    "  x = img_to_array(img)\n",
    "  x /= 255\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "\n",
    "  images = np.vstack([x])\n",
    "  classes = cnn.predict(images, batch_size=10)\n",
    "  print(classes[0])\n",
    "\n",
    "  if classes[0]>0.5:\n",
    "    print(fn + \" is a human\")\n",
    "  else:\n",
    "    print(fn + \" is a horse\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
